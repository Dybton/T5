{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphQL Query Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jakobtolstrup/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jakobtolstrup/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#GraphQL Query Generator\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def generate_graphql_query(input_elements):\n",
    "    while True: # We keep generating queries until we've reached the desired query lenght\n",
    "        query = \"query { \" \n",
    "\n",
    "        entity = random.choice(input_elements[\"entities\"]) #We pick a random entity from the list of entities\n",
    "        query += f\"{entity}\"\n",
    "\n",
    "        arguments_applied = False\n",
    "        \n",
    "        # If less or eq to argument_probability, then true => apply random arguments\n",
    "        \n",
    "        if (random.randint(1, 100) <= input_elements[\"argument_probability\"]):\n",
    "            query += \" ( \"\n",
    "            arguments_applied = True\n",
    "\n",
    "            # Apply limit first\n",
    "            if random.randint(1, 100) <= input_elements[\"limit_probability\"]:\n",
    "                query += f\"limit : {random.randint(1, 20)} , \"\n",
    "\n",
    "            # Apply order_by\n",
    "            if random.randint(1, 100) <= input_elements[\"order_by_probability\"]:\n",
    "                prop = random.choice(input_elements[\"properties\"])\n",
    "                order, _ = random.choices(input_elements[\"orderings\"], [weight for _, weight in input_elements[\"orderings\"]])[0]\n",
    "                query += f\"order_by : {{ {prop} : {order} }} \"\n",
    "\n",
    "            #Apply where clause\n",
    "            if random.randint(1, 100) <= input_elements[\"filter_probability\"]:\n",
    "                query += \"where : { \"\n",
    "\n",
    "                logical_operator = None\n",
    "                logical_operator_applied = False\n",
    "\n",
    "                if random.randint(1, 100) <= input_elements[\"logical_operator_probability\"]:\n",
    "                    logical_operator, _ = random.choices(input_elements[\"logical_operators\"], [weight for _, weight in input_elements[\"logical_operators\"]])[0]\n",
    "                    query += f\"{logical_operator} : \"\n",
    "                    logical_operator_applied = True\n",
    "\n",
    "                if logical_operator_applied:\n",
    "                    query += \"{ \"\n",
    "\n",
    "                if logical_operator_applied and logical_operator == \"_or\":\n",
    "                    query += \"[ \"\n",
    "\n",
    "                prop = random.choice(input_elements[\"properties\"])\n",
    "                comparison_operator, _ = random.choices(input_elements[\"comparison_operators\"], [weight for _, weight in input_elements[\"comparison_operators\"]])[0]\n",
    "                if comparison_operator == \"_like\":\n",
    "                    value = '\"' + f'%{random.choice(input_elements[\"like_arguments\"])}%' + '\"'\n",
    "                else:\n",
    "                    value = round(random.uniform(0, 1000))\n",
    "                query += f\"{{ {prop} : {{ {comparison_operator} : {value} }} }}\"\n",
    "\n",
    "                # Only add a second clause if a logical operator has been applied\n",
    "                if logical_operator_applied:\n",
    "                    if logical_operator == \"_or\":\n",
    "                        query += \" , \"\n",
    "\n",
    "                    if logical_operator == \"_and\":\n",
    "                        query += \" , \"\n",
    "\n",
    "                    prop = random.choice(input_elements[\"properties\"])\n",
    "                    comparison_operator, _ = random.choices(input_elements[\"comparison_operators\"], [weight for _, weight in input_elements[\"comparison_operators\"]])[0]\n",
    "                    if comparison_operator == \"_like\":\n",
    "                        value = '\"' + f'%{random.choice(input_elements[\"like_arguments\"])}%' + '\"'\n",
    "                    else:\n",
    "                        value = round(random.uniform(0, 1000))\n",
    "                    query += f\"{{ {prop} : {{ {comparison_operator} : {value} }} }}\"\n",
    "\n",
    "                if logical_operator_applied:\n",
    "                    if logical_operator == \"_or\":\n",
    "                        query += \" ] \"\n",
    "                    query += \" } }\"\n",
    "\n",
    "\n",
    "            \n",
    "            if random.randint(1, 100) <= input_elements[\"distinct_on_probability\"]:\n",
    "                    prop = random.choice(input_elements[\"properties\"])\n",
    "                    if query.endswith(\"} \"):\n",
    "                        query += f\", distinct_on : {prop} \"\n",
    "                    else:\n",
    "                        query += f\", distinct_on : {prop} \"\n",
    "\n",
    "        if arguments_applied:\n",
    "            query += \" )\"\n",
    "\n",
    "        query += \" { \"\n",
    "\n",
    "        # Select random properties and aggregators to be returned\n",
    "        if random.randint(1, 100) <= input_elements[\"aggregator_probability\"]:\n",
    "            num_aggregators = random.randint(1, len(input_elements[\"aggregators\"]))\n",
    "            for _ in range(num_aggregators):\n",
    "                aggregator, weight = random.choices(input_elements[\"aggregators\"], weights=[w for _, w in input_elements[\"aggregators\"]])[0]\n",
    "                prop = random.choice(input_elements[\"properties\"])\n",
    "                query += f\"{aggregator} {{ {prop} }} \"\n",
    "        else:\n",
    "            # Choose a range of properties based on the property_weights\n",
    "            property_range, _ = random.choices(input_elements[\"property_weights\"], [weight for _, weight in input_elements[\"property_weights\"]])[0]\n",
    "            num_properties = random.randint(1, property_range)\n",
    "            for _ in range(num_properties):\n",
    "                prop = random.choice(input_elements[\"properties\"])\n",
    "                query += f\"{prop} \"\n",
    "                if random.randint(1, 100) <= input_elements[\"nested_probability\"]:\n",
    "                    query += \"{ \"\n",
    "                    # Choose a range of nested properties based on the nested_property_weights \n",
    "                    # Should we also enable the nested queries to have nested queries?\n",
    "                    nested_property_range, _ = random.choices(input_elements[\"nested_property_weights\"], [weight for _, weight in input_elements[\"nested_property_weights\"]])[0]\n",
    "                    nested_properties = [p for p in input_elements[\"properties\"] if p != prop]\n",
    "                    for _ in range(random.randint(1, nested_property_range)):\n",
    "                        nested_prop = random.choice(nested_properties)\n",
    "                        query += f\"{nested_prop} \"\n",
    "                    query += \"} \"\n",
    "\n",
    "        query += \"} }\"\n",
    "\n",
    "        def is_query_length_within_range(query):\n",
    "            rand_num = random.randint(18, 137)\n",
    "            query_length = len(query)\n",
    "            return rand_num - 10 <= query_length <= rand_num + 10\n",
    "\n",
    "        # # To do: Control via weights \n",
    "        # if 80 <= len(query) <= 180:\n",
    "        #     print(query)\n",
    "        #     return query\n",
    "        \n",
    "        if is_query_length_within_range(query):\n",
    "            return query\n",
    "\n",
    "\n",
    "words_list = nltk.corpus.words.words()\n",
    "words_list = [word.lower() for word in words_list]\n",
    "short_words_list = [word for word in words_list if len(word) <= 5]\n",
    "nouns = list({x.name().split('.', 1)[0] for x in wn.all_synsets('n')})\n",
    "\n",
    "# Example input elements\n",
    "input_elements = {  \n",
    "    \"entities\" : random.choices(nouns, k=50000),\n",
    "    \"like_arguments\" : random.choices(nouns, k=10000),\n",
    "    \"properties\" : random.choices(nouns, k=10000),\n",
    "\n",
    "    \"property_weights\": [(1, 50), (2, 37), (3, 15), (4, 3), (5, 0)],\n",
    "    \"nested_property_weights\": [(1, 100), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0)],\n",
    "\n",
    "    \"nested_probability\": 40, \n",
    "    \n",
    "    \"argument_probability\": 83,\n",
    "\n",
    "    \"filter_probability\": 83,\n",
    "\n",
    "    \"order_by_probability\": 39, \n",
    "\n",
    "    \"limit_probability\": 24,\n",
    "\n",
    "    \"distinct_on_probability\": 8,\n",
    "\n",
    "    \"orderings\": [(\"asc\", 10), (\"desc\", 17)],\n",
    "\n",
    "    \"logical_operator_probability\":45,\n",
    "    \n",
    "    \"logical_operators\": [(\"_and\", 50), (\"_or\", 50)],\n",
    "    \n",
    "    \"aggregators\": [(\"min\", 2.2), (\"max\", 5.23), (\"sum\", 2.70), (\"avg\", 6.5)],\n",
    "\n",
    "    \"aggregator_probability\": 9,\n",
    "\n",
    "    \"comparison_operators\": [(\"_eq\", 48), (\"_gt\", 6.71), (\"_lt\", 3.2), (\"lte\", 0.9), (\"gte\", 0.7), (\"_neq\", 2.88), (\"_like\", 2.16)],\n",
    "}\n",
    "\n",
    "# Generate a random GraphQL query\n",
    "\n",
    "#Create a dataframe of random GraphQL queries\n",
    "\n",
    "def create_random_queries(input_elements, num_queries):\n",
    "    queries = []\n",
    "    for _ in range(num_queries):\n",
    "        query = generate_graphql_query(input_elements)\n",
    "        queries.append(query)\n",
    "\n",
    "    data = {'query': queries}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# create_random_queries(input_elements, 10)\n",
    "\n",
    "synthetic_queries_df = create_random_queries(input_elements, 4500)\n",
    "\n",
    "synthetic_queries_df.head()\n",
    "\n",
    "# Save the synthetic queries to a csv file\n",
    "\n",
    "# synthetic_queries_df.to_csv('synthetic.csv', index=False)\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "query_list = synthetic_queries_df.to_dict(orient='records')\n",
    "\n",
    "# Define the file path\n",
    "file_path = './SPEGQL-dataset/dataset/vanilla_error_mirror_4500.json'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# Save the list as a JSON file with consistent formatting\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(query_list, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
