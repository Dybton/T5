{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesting Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to calculate the nesting level of a query\n",
    "def nesting_level(query):\n",
    "    query = re.sub(r'\\s+', '', query)  # Remove whitespace\n",
    "    max_nesting = 0\n",
    "    current_nesting = 0\n",
    "\n",
    "    for char in query:\n",
    "        if char == '{':\n",
    "            current_nesting += 1\n",
    "            max_nesting = max(max_nesting, current_nesting)\n",
    "        elif char == '}':\n",
    "            current_nesting -= 1\n",
    "\n",
    "    return max_nesting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Num Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_graphql_arguments(query: str) -> int:\n",
    "    # Removing white spaces and escape characters\n",
    "    query = re.sub(r'\\s|\\\\', '', query)\n",
    "    \n",
    "    # Regular expression to find arguments in the query\n",
    "    pattern = re.compile(r'(\\{[^\\{]*\\})')\n",
    "    matches = pattern.findall(query)\n",
    "\n",
    "    # Counting the number of arguments\n",
    "    count = 0\n",
    "    for match in matches:\n",
    "        count += match.count(':')\n",
    "    return count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Schema Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'schema_folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length \u001b[39m=\u001b[39m analyze_schema_complexity(schema_json)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m## Call the function on all schemas and add the counts and complexity score to the DataFrame\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m schema_folder \u001b[39min\u001b[39;00m schema_folders:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(schemas_folder, schema_folder)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(schemas_folder, schema_folder, \u001b[39m'\u001b[39m\u001b[39mschema.json\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m schema_file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'schema_folders' is not defined"
     ]
    }
   ],
   "source": [
    "weight_types = 1\n",
    "weight_fields = 1\n",
    "weight_input_objects = 1\n",
    "weight_relationships = 2\n",
    "weight_arguments = 1\n",
    "\n",
    "def analyze_schema_complexity(schema_json):\n",
    "    types_count = 0\n",
    "    fields_count = 0\n",
    "    input_objects_count = 0\n",
    "    relationships_count = 0\n",
    "    arguments_count = 0\n",
    "\n",
    "    for type_ in schema_json[\"__schema\"][\"types\"]:\n",
    "        types_count += 1\n",
    "\n",
    "        if type_[\"kind\"] == \"INPUT_OBJECT\":\n",
    "            input_objects_count += 1\n",
    "\n",
    "        if \"fields\" in type_ and type_[\"fields\"] is not None:\n",
    "            for field in type_[\"fields\"]:\n",
    "                fields_count += 1\n",
    "\n",
    "                if \"args\" in field:\n",
    "                    arguments_count += len(field[\"args\"])\n",
    "                    relationships_count += 1\n",
    "\n",
    "    complexity_score = (\n",
    "    (types_count * weight_types)\n",
    "    + (fields_count * weight_fields)\n",
    "    + (input_objects_count * weight_input_objects)\n",
    "    + (relationships_count * weight_relationships)\n",
    "    + (arguments_count * weight_arguments)\n",
    ")\n",
    "\n",
    "    schema_length = len(json.dumps(schema_json))\n",
    "\n",
    "    return complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length\n",
    "\n",
    "# Load your GraphQL schema JSON file\n",
    "import json\n",
    "\n",
    "with open(\"SPEGQL-dataset/Schemas/activity_1/schema.json\", \"r\") as file:\n",
    "    schema_json = json.load(file)\n",
    "\n",
    "complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length = analyze_schema_complexity(schema_json)\n",
    "\n",
    "## Call the function on all schemas and add the counts and complexity score to the DataFrame\n",
    "for schema_folder in schema_folders:\n",
    "    if os.path.isdir(os.path.join(schemas_folder, schema_folder)):\n",
    "        with open(os.path.join(schemas_folder, schema_folder, 'schema.json'), 'r') as schema_file:\n",
    "            schema_json = json.load(schema_file)\n",
    "            complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length = analyze_schema_complexity(schema_json)\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_total_complexity'] = complexity_score\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_types_count'] = types_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_fields_count'] = fields_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_input_objects_count'] = input_objects_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_relationships_count'] = relationships_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_arguments_count'] = arguments_count\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Query Components Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_query_components(df):\n",
    "\n",
    "    # Define component types\n",
    "    arguments = [\"\\\\(\"]\n",
    "    filters = [\"where\"]\n",
    "    query_modifiers = [\"order_by\", \"limit\", \"distinct_on\"]\n",
    "    logical_operators = [\"_and\", \"_or\", \"_not\"]\n",
    "    comparison_operators = [\"_eq\", \"_neq\", \"_lt\", \"_gt\", \"_lte\", \"_gte\", \"_like\"]\n",
    "    aggregators = [\"min\", \"max\", \"sum\", \"avg\"]\n",
    "    orderings = [\"asc\", \"desc\"]\n",
    "\n",
    "    # Create a dictionary of the component types\n",
    "    component_types = {\n",
    "        \"arguments\": arguments,\n",
    "        \"filters\": filters,\n",
    "        \"query_modifiers\": query_modifiers,\n",
    "        \"logical_operators\": logical_operators,\n",
    "        \"comparison_operators\": comparison_operators,\n",
    "        \"aggregators\": aggregators,\n",
    "        \"orderings\": orderings\n",
    "    }\n",
    "\n",
    "    # Create an empty dataframe to store the results, initalized with the columns we want\n",
    "    results_df = pd.DataFrame(columns=[\"Component_Type\", \"Component\", \"Value\"])\n",
    "\n",
    "    # Iterate through the component types and count the number of times each component appears in the query\n",
    "    for component_type, components in component_types.items(): # .items() returns a tuple of the key and value, in this case the key is the component type and the value is the list of components\n",
    "        # We initalize components_counts. This is a dictionary where the key is the component and the value is the number of times that component appears in the query\n",
    "        component_counts = {component: 0 for component in components} \n",
    "        total_components = 0\n",
    "\n",
    "        # Iterate through each component and count the number of times it appears in the query\n",
    "        for component in components:\n",
    "            component_count = df['query'].str.count(component).sum() # .str.count() counts the number of times a string appears in a column, we sum this to get the total number of times the component appears in the column\n",
    "            component_counts[component] = component_count # Add the component count to the component_counts dictionary\n",
    "            total_components += component_count # Add the component count to the total_components count\n",
    "\n",
    "            component_percent = (component_count / len(df)) * 100 # Calculate the percentage of queries that contain the component\n",
    "\n",
    "            new_row = pd.DataFrame({\n",
    "                \"Component_Type\": [f\"{component_type} relative\"],\n",
    "                \"Component\": [component],\n",
    "                \"Value\": [component_percent]\n",
    "            })\n",
    "\n",
    "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        total_percent_components = (total_components / len(df)) * 100\n",
    "\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [f\"{component_type} relative (total)\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [total_percent_components]\n",
    "        })\n",
    "\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Calculate the average nesting level\n",
    "    avg_nesting = df['query'].apply(nesting_level).mean()\n",
    "\n",
    "    # Add the average nesting level to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"avg_nesting_level\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [avg_nesting]\n",
    "    })\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Calculate the average number of GraphQL arguments\n",
    "    avg_args = df['query'].apply(count_graphql_arguments).mean()\n",
    "\n",
    "    # Add the average number of GraphQL arguments to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"avg_graphql_arguments\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [avg_args]\n",
    "    })\n",
    "\n",
    "    # Calculate the length of each query\n",
    "    df['query_length'] = df['query'].str.len()\n",
    "\n",
    "    # Calculate max, min and avg query length\n",
    "    max_query_length = df['query_length'].max()\n",
    "    min_query_length = df['query_length'].min()\n",
    "    avg_query_length = df['query_length'].mean()\n",
    "\n",
    "    # Add max query length to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"max_query_length\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [max_query_length]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Add min query length to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"min_query_length\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [min_query_length]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Add avg query length to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"avg_query_length\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [avg_query_length]\n",
    "    })\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    if 'question_length' in df.columns:\n",
    "        # Calculate max, min and avg question length\n",
    "        max_question_length = df['question_length'].max()\n",
    "        min_question_length = df['question_length'].min()\n",
    "        avg_question_length = df['question_length'].mean()\n",
    "\n",
    "        # Add max question length to the results dataframe\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [\"max_question_length\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [max_question_length]\n",
    "        })\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        # Add min question length to the results dataframe\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [\"min_question_length\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [min_question_length]\n",
    "        })\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        # Add avg question length to the results dataframe\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [\"avg_question_length\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [avg_question_length]\n",
    "        })\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    return results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7048a5d75593413cc54dc24206831079ac8905ffddb319c4eafd454be0ec5d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
