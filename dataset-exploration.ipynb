{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesting Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to calculate the nesting level of a query\n",
    "def nesting_level(query):\n",
    "    query = re.sub(r'\\s+', '', query)  # Remove whitespace\n",
    "    max_nesting = 0\n",
    "    current_nesting = 0\n",
    "\n",
    "    for char in query:\n",
    "        if char == '{':\n",
    "            current_nesting += 1\n",
    "            max_nesting = max(max_nesting, current_nesting)\n",
    "        elif char == '}':\n",
    "            current_nesting -= 1\n",
    "\n",
    "    return max_nesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Function that calculate the nesting level for each query and add it as a new column\n",
    "dev['nesting_level'] = dev['query'].apply(nesting_level)\n",
    "\n",
    "test = True\n",
    "stats = False\n",
    "\n",
    "if test:\n",
    "    query1 = 'query{teacher(where:{_or:[{age:{_eq:\\\"32\\\"}},{age:{_eq:\\\"33\\\"}}]}){name}}'\n",
    "    print(nesting_level(query1))\n",
    "    query2 = 'query { templates ( where : { _and : [ { template_type_code : { _neq : \"PP\" } } , { template_type_code : { _neq : \"PPT\" } } ] } ) { template_id template_type_code } }'\n",
    "    print(nesting_level(query2))\n",
    "    query3 = 'query { countrylanguage ( where : { language : { _neq : \\\"French\\\" } } , distinct_on : countrycode ) { countrycode } }'\n",
    "    print(nesting_level(query3))\n",
    "    query4 = 'query { matches_aggregate { aggregate { count } } }'\n",
    "    print(nesting_level(query4))\n",
    "    query5 = 'query{singer_aggregate(where:{country:{_eq:\\\"France\\\"}}){aggregate{avg{age}min{age}max{age}}}}'\n",
    "    print(nesting_level(query5))\n",
    "\n",
    "if stats:\n",
    "    # calculate the mean, median, min, and max of nesting levels\n",
    "    mean_nesting = dev['nesting_level'].mean()\n",
    "    median_nesting = dev['nesting_level'].median()\n",
    "    min_nesting = dev['nesting_level'].min()\n",
    "    max_nesting = dev['nesting_level'].max()\n",
    "\n",
    "    print(f\"Mean nesting level: {mean_nesting}\")\n",
    "    print(f\"Median nesting level: {median_nesting}\")\n",
    "    print(f\"Minimum nesting level: {min_nesting}\")\n",
    "    print(f\"Maximum nesting level: {max_nesting}\")\n",
    "\n",
    "    # plot a histogram of the nesting levels\n",
    "    plt.hist(dev['nesting_level'], edgecolor='black')\n",
    "    plt.xlabel('Nesting Level')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Nesting Levels')\n",
    "    plt.show()\n",
    "\n",
    "    dev[dev['nesting_level'] == 2].shape[0]\n",
    "    print(\"Nesting level 2 \" + str(dev[dev['nesting_level'] == 2].shape[0]))\n",
    "    print(\"Nesting level 3 \" + str(dev[dev['nesting_level'] == 3].shape[0]))\n",
    "    print(\"Nesting level 4 \" + str(dev[dev['nesting_level'] == 4].shape[0]))\n",
    "    print(\"Nesting level 5 \" + str(dev[dev['nesting_level'] == 5].shape[0]))\n",
    "    print(\"Nesting level 6 \" + str(dev[dev['nesting_level'] == 6].shape[0]))\n",
    "\n",
    "    dev.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_graphql_arguments(query: str) -> int:\n",
    "    # Removing white spaces and escape characters\n",
    "    query = re.sub(r'\\s|\\\\', '', query)\n",
    "    \n",
    "    # Regular expression to find arguments in the query\n",
    "    pattern = re.compile(r'(\\{[^\\{]*\\})')\n",
    "    matches = pattern.findall(query)\n",
    "\n",
    "    # Counting the number of arguments\n",
    "    count = 0\n",
    "    for match in matches:\n",
    "        count += match.count(':')\n",
    "    return count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#dev['num_args'] = dev['query'].apply(count_query_arguments)\n",
    "\n",
    "test = False\n",
    "stats = False\n",
    "\n",
    "if test:\n",
    "    query1 = 'query{teacher(where:{_or:[{age:{_eq:\\\"32\\\"}},{age:{_eq:\\\"33\\\"}}]}){name}}'\n",
    "    print(count_graphql_arguments(query1))  # Output: 2\n",
    "    query2 = 'query { templates ( where : { _and : [ { template_type_code : { _neq : \"PP\" } } , { template_type_code : { _neq : \"PPT\" } } ] } ) { template_id template_type_code } }'\n",
    "    print(count_graphql_arguments(query2))  # Output: 2\n",
    "    query3 = 'query { countrylanguage ( where : { language : { _neq : \\\"French\\\" } } , distinct_on : countrycode ) { countrycode } }'\n",
    "    print(count_graphql_arguments(query3))  # Output: 2\n",
    "    query4 = 'query { matches_aggregate { aggregate { count } } }'\n",
    "    print(count_graphql_arguments(query4))  # Output: 0\n",
    "    query5 = 'query{singer_aggregate(where:{country:{_eq:\\\"France\\\"}}){aggregate{avg{age}min{age}max{age}}}}'\n",
    "    print(count_graphql_arguments(query5))  # Output: 1\n",
    "    query6 = 'query { tv_channel_aggregate ( where : { language : { _eq : \\\"English\\\" } } ) { aggregate { count } } }'\n",
    "    print(count_graphql_arguments(query6))  # Output: 1\n",
    "    query7 = '{ conductor ( where : { orchestras : { year_of_founded : { _gt : 2008.0 } } } ) { name } }'\n",
    "    print(count_graphql_arguments(query7))  # Output: 1\n",
    "    query8 = '{ flights_aggregate ( where : { sourceairport : { _eq : \\\"APG\\\" } } ) { aggregate { count } } }'\n",
    "    print(count_graphql_arguments(query8))  # Output: 1\n",
    "    query9 = '{ poker_player_aggregate ( where : { earnings : { _lt : 200000.0 } } ) { aggregate { max { final_table_made } } } }'\n",
    "    print(count_graphql_arguments(query9))  # Output: 1\n",
    "    query10 = '{ country_aggregate ( where : { _and : { continent : { _eq : \\\"Africa\\\" } , governmentform : { _eq : \\\"Republic\\\" } } } ) { aggregate { avg { lifeexpectancy } } } }'\n",
    "    print(count_graphql_arguments(query10))  # Output: 2\n",
    "    query11 = '{ matches_aggregate ( where : { _and : { winner_hand : { _eq : \\\"L\\\" } , tourney_name : { _eq : \\\"WTA Championships\\\" } } } ) { aggregate { count } } }'\n",
    "    print(count_graphql_arguments(query11))  # Output: 2\n",
    "    query12 =  '{ paragraphs_aggregate ( where : { document : { document_name : { _eq : \\\"Summer Show\\\" } } } ) { aggregate { count } } }'\n",
    "    print(count_graphql_arguments(query12))  # Output: 1\n",
    "\n",
    "if stats:\n",
    "    dev['num_args'].hist()\n",
    "\n",
    "    print(dev['num_args'].min())\n",
    "    print(dev['num_args'].max())\n",
    "\n",
    "    print(dev['num_args'].mean())\n",
    "    print(dev['num_args'].median())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addding length and schemaId to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def add_schema_info(df):\n",
    "    schemas_folder = 'SPEGQL-dataset/Schemas'\n",
    "    schema_folders = sorted(os.listdir(schemas_folder), key=lambda x: os.path.getmtime(os.path.join(schemas_folder, x)))\n",
    "\n",
    "    for schema_folder in schema_folders:\n",
    "        if os.path.isdir(os.path.join(schemas_folder, schema_folder)):\n",
    "            with open(os.path.join(schemas_folder, schema_folder, 'schema.json'), 'r') as schema_file:\n",
    "                schema_length = sum(1 for line in schema_file)\n",
    "\n",
    "            new_row = pd.DataFrame({'schemaId': [schema_folder], 'schema_length': [schema_length]})\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Create an empty DataFrame with the specified columns\n",
    "data = {'schemaId': [], 'schema_length': []}\n",
    "\n",
    "# create a dataframe from dev_df_with_results.csv\n",
    "dev_df = pd.read_csv('dev_df_with_results.csv')\n",
    "\n",
    "# add schema info to the dataframe\n",
    "dev_df = add_schema_info(dev_df)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Schema Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'schema_folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length \u001b[39m=\u001b[39m analyze_schema_complexity(schema_json)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m## Call the function on all schemas and add the counts and complexity score to the DataFrame\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m schema_folder \u001b[39min\u001b[39;00m schema_folders:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(schemas_folder, schema_folder)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(schemas_folder, schema_folder, \u001b[39m'\u001b[39m\u001b[39mschema.json\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m schema_file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'schema_folders' is not defined"
     ]
    }
   ],
   "source": [
    "weight_types = 1\n",
    "weight_fields = 1\n",
    "weight_input_objects = 1\n",
    "weight_relationships = 2\n",
    "weight_arguments = 1\n",
    "\n",
    "def analyze_schema_complexity(schema_json):\n",
    "    types_count = 0\n",
    "    fields_count = 0\n",
    "    input_objects_count = 0\n",
    "    relationships_count = 0\n",
    "    arguments_count = 0\n",
    "\n",
    "    for type_ in schema_json[\"__schema\"][\"types\"]:\n",
    "        types_count += 1\n",
    "\n",
    "        if type_[\"kind\"] == \"INPUT_OBJECT\":\n",
    "            input_objects_count += 1\n",
    "\n",
    "        if \"fields\" in type_ and type_[\"fields\"] is not None:\n",
    "            for field in type_[\"fields\"]:\n",
    "                fields_count += 1\n",
    "\n",
    "                if \"args\" in field:\n",
    "                    arguments_count += len(field[\"args\"])\n",
    "                    relationships_count += 1\n",
    "\n",
    "    complexity_score = (\n",
    "    (types_count * weight_types)\n",
    "    + (fields_count * weight_fields)\n",
    "    + (input_objects_count * weight_input_objects)\n",
    "    + (relationships_count * weight_relationships)\n",
    "    + (arguments_count * weight_arguments)\n",
    ")\n",
    "\n",
    "    schema_length = len(json.dumps(schema_json))\n",
    "\n",
    "    return complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length\n",
    "\n",
    "# Load your GraphQL schema JSON file\n",
    "import json\n",
    "\n",
    "with open(\"SPEGQL-dataset/Schemas/activity_1/schema.json\", \"r\") as file:\n",
    "    schema_json = json.load(file)\n",
    "\n",
    "complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length = analyze_schema_complexity(schema_json)\n",
    "\n",
    "## Call the function on all schemas and add the counts and complexity score to the DataFrame\n",
    "for schema_folder in schema_folders:\n",
    "    if os.path.isdir(os.path.join(schemas_folder, schema_folder)):\n",
    "        with open(os.path.join(schemas_folder, schema_folder, 'schema.json'), 'r') as schema_file:\n",
    "            schema_json = json.load(schema_file)\n",
    "            complexity_score, types_count, fields_count, input_objects_count, relationships_count, arguments_count, schema_length = analyze_schema_complexity(schema_json)\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_total_complexity'] = complexity_score\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_types_count'] = types_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_fields_count'] = fields_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_input_objects_count'] = input_objects_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_relationships_count'] = relationships_count\n",
    "            df.loc[df['schemaId'] == schema_folder, 'schema_arguments_count'] = arguments_count\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity score: (21, 3, 5, 1, 2, 8, 475)\n"
     ]
    }
   ],
   "source": [
    "## Test \n",
    "\n",
    "# Sample GraphQL schema in JSON format\n",
    "sample_schema = {\n",
    "    \"__schema\": {\n",
    "        \"types\": [\n",
    "            {\n",
    "                \"kind\": \"OBJECT\",\n",
    "                \"name\": \"query_root\",\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"author\",\n",
    "                        \"args\": [\n",
    "                            {\"name\": \"limit\"},\n",
    "                            {\"name\": \"offset\"},\n",
    "                            {\"name\": \"order_by\"},\n",
    "                            {\"name\": \"where\"},\n",
    "                        ],\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"author_aggregate\",\n",
    "                        \"args\": [\n",
    "                            {\"name\": \"distinct_on\"},\n",
    "                            {\"name\": \"limit\"},\n",
    "                            {\"name\": \"offset\"},\n",
    "                            {\"name\": \"order_by\"},\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"kind\": \"OBJECT\",\n",
    "                \"name\": \"author\",\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"id\"},\n",
    "                    {\"name\": \"name\"},\n",
    "                    {\"name\": \"birthdate\"},\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"kind\": \"INPUT_OBJECT\",\n",
    "                \"name\": \"author_bool_exp\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Run the analyze_schema_complexity function with the sample schema\n",
    "complexity_score = analyze_schema_complexity(sample_schema)\n",
    "print(\"Complexity score:\", complexity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to next line\n",
    "pd.set_option('display.max_colwidth', None)  # Show the full content of each cell\n",
    "\n",
    "test_queries = [\n",
    "'query { hiring { employee_id is_full_time shop_id start_from } }',\n",
    "'query { teacher ( order_by : { age : asc } ) { name } }',\n",
    "'query { pets ( where : { pet_age : { _gt : 1 } } ) { petid weight } }',\n",
    "'query { singer_aggregate { aggregate { count } } }',\n",
    "'query { singer { birth_year citizenship } }',\n",
    "'query { ref_template_types { template_type_code template_type_description } }',\n",
    "'query { airports ( where : { city : { _eq : \"Anthony\" } } ) { airportcode airportname }}',\n",
    "'query { singer ( where : { song_name : { _like : \"%Hey%\" } } ) { name country } }',\n",
    "'query { players ( order_by : { birth_date : asc } ) { first_name last_name } }',\n",
    "'query { battle ( where : { bulgarian_commander : { _neq : \"Boril\" } } ) { name result } }',\n",
    "'query { stadium ( where : { capacity : { _gte : 5000 , _lte : 10000 } } ) { location name } }',\n",
    "'query { country_aggregate ( where : { continent : { _eq : \"Africa\" } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }',\n",
    "'query { country_aggregate ( where : { governmentform : { _eq : \"Republic\" } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { _and : { flights : { sourceairport : { _eq : \"AHD\" } } , airline : { _eq : \"United Airlines\" } } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { destairport : { _eq : \"ASY\" } } } } ) { aggregate { count } } }',\n",
    "'query { paragraphs_aggregate ( where : { document : { document_name : { _eq : \"Summer Show\" } } } ) { aggregate { count } } }',\n",
    "'query { country_aggregate ( where : { _and : { countrylanguages : { isofficial : { _eq : \"T\" } } , name : { _eq : \"Afghanistan\" } } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { _and : { flights : { sourceairport : { _eq : \"AHD\" } } , airline : { _eq : \"United Airlines\" } } } ) { aggregate { count } } }'\n",
    "]\n",
    "\n",
    "reordered_queries = [\n",
    "'query { hiring { employee_id shop_id is_full_time start_from } }',\n",
    "'query { teacher ( order_by : { age : asc } ) { name } }',\n",
    "'query { pets ( where : { pet_age : { _gt : 1 } } ) { weight petid } }',\n",
    "'query { singer_aggregate { aggregate { count } } }',\n",
    "'query { singer { citizenship birth_year } }',\n",
    "'query { ref_template_types { template_type_description template_type_code } }',\n",
    "'query { airports ( where : { city : { _eq : \"Anthony\" } } ) { airportname airportcode }}',\n",
    "'query { singer ( where : { song_name : { _like : \"%Hey%\" } } ) { country name } }',\n",
    "'query { players ( order_by : { birth_date : asc } ) { last_name first_name } }',\n",
    "'query { battle ( where : { bulgarian_commander : { _neq : \"Boril\" } } ) { result name } }',\n",
    "'query { stadium ( where : { capacity : { _gte : 5000 , _lte : 10000 } } ) { name location } }',\n",
    "'query { country_aggregate ( where : { continent : { _eq : \"Africa\" } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }',\n",
    "'query { country_aggregate ( where : { governmentform : { _eq : \"Republic\" } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { sourceairport : { _eq : \"AHD\" } } } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { destairport : { _eq : \"ASY\" } } } } ) { aggregate { count } } }',\n",
    "'query { paragraphs_aggregate ( where : { document : { document_name : { _eq : \"Summer Show\" } } } ) { aggregate { count } } }',\n",
    "'query { country_aggregate ( where : { _and : { name : { _eq : \"Afghanistan\" } , countrylanguages : { isofficial : { _eq : \"T\" } } } } ) { aggregate { count } } }',\n",
    "'query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { sourceairport : { _eq : \"AHD\" } } } } ) { aggregate { count } } }'\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with column names as keys and lists as values\n",
    "data = {\n",
    "    \"queries\": test_queries,\n",
    "    \"queries_shifted_order\": reordered_queries\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame using the dictionary\n",
    "df_test_queries = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_test_queries\n",
    "\n",
    "## Save df_test_queries to a csv file called semantic_match_test_queries.csv\n",
    "\n",
    "df_test_queries.to_csv('semantic_match_test_queries.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Of Failed Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to next line\n",
    "pd.set_option('display.max_colwidth', None)  # Show the full content of each cell\n",
    "\n",
    "df_dev = pd.read_csv('dev_df_with_results.csv')\n",
    "\n",
    "df_dev = df_dev[df_dev.semantic_match == 0]\n",
    "\n",
    "df_dev['error_reason'] = ''\n",
    "\n",
    "df_dev = df_dev[['question', 'query', 'predicted_query', 'error_reason', 'exact_match', 'num_args', 'nesting_level', 'schema_total_complexity']]\n",
    "\n",
    "df_dev.sample(50).to_csv('qualitative_analysis.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_dev \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdev_df_with_results.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# The rows where rows where semantic_match_result is different from exact_match\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jakobtolstrup/Desktop/Thesis/myvenv/T5-Carrera/dataset-exploration.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_dev[df_dev\u001b[39m.\u001b[39msemantic_match \u001b[39m!=\u001b[39m df_dev\u001b[39m.\u001b[39mexact_match]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_dev = pd.read_csv('dev_df_with_results.csv')\n",
    "\n",
    "# The rows where rows where semantic_match_result is different from exact_match\n",
    "\n",
    "df_dev[df_dev.semantic_match != df_dev.exact_match]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Query Components Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_query_components(df):\n",
    "\n",
    "    # Define component types\n",
    "    arguments = [\"\\\\(\"]\n",
    "    filters = [\"where\"]\n",
    "    query_modifiers = [\"order_by\", \"limit\", \"distinct_on\"]\n",
    "    logical_operators = [\"_and\", \"_or\", \"_not\"]\n",
    "    comparison_operators = [\"_eq\", \"_neq\", \"_lt\", \"_gt\", \"_lte\", \"_gte\", \"_like\"]\n",
    "    aggregators = [\"min\", \"max\", \"sum\", \"avg\"]\n",
    "    orderings = [\"asc\", \"desc\"]\n",
    "\n",
    "    # Create a dictionary of the component types\n",
    "    component_types = {\n",
    "        \"arguments\": arguments,\n",
    "        \"filters\": filters,\n",
    "        \"query_modifiers\": query_modifiers,\n",
    "        \"logical_operators\": logical_operators,\n",
    "        \"comparison_operators\": comparison_operators,\n",
    "        \"aggregators\": aggregators,\n",
    "        \"orderings\": orderings\n",
    "    }\n",
    "\n",
    "    # Create an empty dataframe to store the results, initalized with the columns we want\n",
    "    results_df = pd.DataFrame(columns=[\"Component_Type\", \"Component\", \"Value\"])\n",
    "\n",
    "    # Iterate through the component types and count the number of times each component appears in the query\n",
    "    for component_type, components in component_types.items(): # .items() returns a tuple of the key and value, in this case the key is the component type and the value is the list of components\n",
    "        # We initalize components_counts. This is a dictionary where the key is the component and the value is the number of times that component appears in the query\n",
    "        component_counts = {component: 0 for component in components} \n",
    "        total_components = 0\n",
    "\n",
    "        # Iterate through each component and count the number of times it appears in the query\n",
    "        for component in components:\n",
    "            component_count = df['query'].str.count(component).sum() # .str.count() counts the number of times a string appears in a column, we sum this to get the total number of times the component appears in the column\n",
    "            component_counts[component] = component_count # Add the component count to the component_counts dictionary\n",
    "            total_components += component_count # Add the component count to the total_components count\n",
    "\n",
    "            component_percent = (component_count / len(df)) * 100 # Calculate the percentage of queries that contain the component\n",
    "\n",
    "            new_row = pd.DataFrame({\n",
    "                \"Component_Type\": [f\"{component_type} relative\"],\n",
    "                \"Component\": [component],\n",
    "                \"Value\": [component_percent]\n",
    "            })\n",
    "\n",
    "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        total_percent_components = (total_components / len(df)) * 100\n",
    "\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [f\"{component_type} relative (total)\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [total_percent_components]\n",
    "        })\n",
    "\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Calculate the average nesting level\n",
    "    avg_nesting = df['query'].apply(nesting_level).mean()\n",
    "\n",
    "    # Add the average nesting level to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"avg_nesting_level\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [avg_nesting]\n",
    "    })\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Calculate the average number of GraphQL arguments\n",
    "    avg_args = df['query'].apply(count_graphql_arguments).mean()\n",
    "\n",
    "    # Add the average number of GraphQL arguments to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"avg_graphql_arguments\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [avg_args]\n",
    "    })\n",
    "\n",
    "    # Calculate the length of each query\n",
    "    df['query_length'] = df['query'].str.len()\n",
    "\n",
    "    # Calculate max, min and avg query length\n",
    "    max_query_length = df['query_length'].max()\n",
    "    min_query_length = df['query_length'].min()\n",
    "    avg_query_length = df['query_length'].mean()\n",
    "\n",
    "    # Add max query length to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"max_query_length\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [max_query_length]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Add min query length to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"min_query_length\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [min_query_length]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Add avg query length to the results dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Component_Type\": [\"avg_query_length\"],\n",
    "        \"Component\": [\"\"],\n",
    "        \"Value\": [avg_query_length]\n",
    "    })\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    if 'question_length' in df.columns:\n",
    "        # Calculate max, min and avg question length\n",
    "        max_question_length = df['question_length'].max()\n",
    "        min_question_length = df['question_length'].min()\n",
    "        avg_question_length = df['question_length'].mean()\n",
    "\n",
    "        # Add max question length to the results dataframe\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [\"max_question_length\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [max_question_length]\n",
    "        })\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        # Add min question length to the results dataframe\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [\"min_question_length\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [min_question_length]\n",
    "        })\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        # Add avg question length to the results dataframe\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Component_Type\": [\"avg_question_length\"],\n",
    "            \"Component\": [\"\"],\n",
    "            \"Value\": [avg_question_length]\n",
    "        })\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    return results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7048a5d75593413cc54dc24206831079ac8905ffddb319c4eafd454be0ec5d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
