{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakobtolstrup/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/jakobtolstrup/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 6): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE\n",
      "  Referenced from: /Users/jakobtolstrup/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in: /Users/jakobtolstrup/opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      " in /Users/jakobtolstrup/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7fa1366630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, ConcatDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from functools import partial\n",
    "from transformers import get_linear_schedule_with_warmup, AutoConfig \n",
    "from transformers import BartTokenizer,BartModel,BartForConditionalGeneration\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Model\n",
    "from transformers import BartConfig\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AdamW\n",
    "from torch.autograd import Variable\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import socket\n",
    "from os.path import basename\n",
    "from functools import reduce\n",
    "import re\n",
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import sys\n",
    "import subprocess\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my version of transformers is 4.15.0\n",
      "my version of pytorch is 1.10.0\n",
      "my version of pytorch_lightning is 1.9.3\n"
     ]
    }
   ],
   "source": [
    "print(\"my version of transformers is \" + transformers.__version__)\n",
    "print (\"my version of pytorch is \" + torch.__version__)\n",
    "print(\"my version of pytorch_lightning is \" + pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### States\n",
    "test_state = False\n",
    "tensorflow_active = True\n",
    "use_gpu = False\n",
    "train_state = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToGraphQLDataset(Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, tokenizer, type_path='train.json', block_size=102):\n",
    "        'Initialization'\n",
    "        super(TextToGraphQLDataset, ).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.source = []\n",
    "        self.target = []\n",
    "        self.schema_ids = []\n",
    "        root_path = './SPEGQL-dataset/'\n",
    "        dataset_path = root_path + 'dataset/' + type_path\n",
    "\n",
    "        schemas_path = root_path + 'Schemas/'\n",
    "        schemas = glob.glob(schemas_path + '**/' + 'simpleSchema.json')\n",
    "\n",
    "        self.max_len = 0\n",
    "        self.name_to_schema = {}\n",
    "        for schema_path in schemas:\n",
    "           with open(schema_path, 'r', encoding='utf-8') as s:\n",
    "            \n",
    "             data = json.load(s)\n",
    "\n",
    "             type_field_tokens = [ ['<t>'] + [t['name']] + ['{'] + [ f['name'] for f in t['fields']] + ['}'] + ['</t>'] for t in data['types']]\n",
    "             type_field_flat_tokens = reduce(list.__add__, type_field_tokens)\n",
    "\n",
    "             arguments = [a['name']  for a in data['arguments']]\n",
    "             schema_tokens = type_field_flat_tokens + ['<a>'] + arguments + ['</a>']\n",
    "\n",
    "             path = Path(schema_path)\n",
    "             schema_name = basename(str(path.parent))\n",
    "\n",
    "             self.name_to_schema[schema_name] = schema_tokens\n",
    "\n",
    "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "          data = json.load(f)\n",
    "\n",
    "          for element in data:\n",
    "            question_with_schema = 'translate English to GraphQL: ' + element['question']  + ' ' + ' '.join(self.name_to_schema[element['schemaId']])\n",
    "            tokenized_s = tokenizer.encode_plus(question_with_schema,max_length=1024, padding=True, truncation=True, return_tensors='pt')\n",
    "            self.source.append(tokenized_s)\n",
    "\n",
    "            tokenized_t = tokenizer.encode_plus(element['query'],max_length=block_size, padding='max_length', truncation=True, return_tensors='pt')\n",
    "            self.target.append(tokenized_t)\n",
    "            self.schema_ids.append(element['schemaId'])\n",
    "\n",
    "  def get_question_with_schema(self, question, schemaId):\n",
    "        return 'translate English to GraphQL: ' + question  + ' ' + ' '.join(self.name_to_schema[schemaId])\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.source)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        source_ids = self.source[index]['input_ids'].squeeze()\n",
    "        target_ids = self.target[index]['input_ids'].squeeze()\n",
    "        src_mask = self.source[index]['attention_mask'].squeeze()\n",
    "\n",
    "        return { \n",
    "            'source_ids': source_ids,\n",
    "                'source_mask': src_mask,\n",
    "                'target_ids': target_ids,\n",
    "                'target_ids_y': target_ids\n",
    "                }\n",
    "\n",
    "sys.modules[\"__main__\"].TextToGraphQLDataset = TextToGraphQLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_state:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "    dataset = TextToGraphQLDataset(tokenizer=tokenizer, type_path='train.json', block_size=102)\n",
    "\n",
    "    length = dataset.__len__()\n",
    "    item = dataset.__getitem__(0)\n",
    "    print(\"TextToGraphQLDataset test done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskGraphQLDataset(Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, tokenizer, type_path='train.json', block_size=64):\n",
    "        'Initialization'\n",
    "        super(MaskGraphQLDataset, ).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.source = []\n",
    "        self.target = []\n",
    "        path = './SPEGQL-dataset/dataset/' + type_path\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "          data = json.load(f)\n",
    "          for example in data:\n",
    "\n",
    "            utterance = example['query']\n",
    "            encoded_source = tokenizer.encode(utterance, max_length=block_size, padding='max_length', truncation=True, return_tensors='pt').squeeze()\n",
    "            token_count = encoded_source.shape[0]\n",
    "            repeated_utterance = [encoded_source for _ in range(token_count)]\n",
    "            for pos in range(1, token_count):\n",
    "              encoded_source = repeated_utterance[pos].clone()\n",
    "              target_id = encoded_source[pos].item()\n",
    "              if target_id == tokenizer.eos_token_id:\n",
    "                  break\n",
    "              encoded_source[pos] = tokenizer.mask_token_id\n",
    "              decoded_target = ''.join(tokenizer.convert_ids_to_tokens([target_id]))\n",
    "              encoded_target = tokenizer.encode(decoded_target, return_tensors='pt', max_length=4, padding='max_length', truncation=True).squeeze()\n",
    "              if encoded_target is not None and torch.numel(encoded_target) > 0:\n",
    "                  self.target.append(encoded_target)\n",
    "                  self.source.append(encoded_source)\n",
    "              if torch.numel(encoded_target) > 0:\n",
    "                  self.target.append(encoded_target)\n",
    "                  self.source.append(encoded_source)\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.source)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        source_ids = self.source[index]\n",
    "        target_id = self.target[index]\n",
    "        return { 'source_ids': source_ids,\n",
    "                'target_id': target_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_state:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "    special_tokens_dict = tokenizer.special_tokens_map # the issue could be here, might need to copy.\n",
    "    special_tokens_dict['mask_token'] = '<mask>'\n",
    "    special_tokens_dict['additional_special_tokens'] = ['<t>', '</t>', '<a>', '</a>']\n",
    "    tokenizer.add_tokens(['{', '}', '<c>', '</c>'])\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    #model.resize_token_embeddings(len(tokenizer))\n",
    "    print(tokenizer.mask_token)\n",
    "\n",
    "    dataset = MaskGraphQLDataset(tokenizer=tokenizer, type_path='train.json', block_size=64)\n",
    "    print(\"MaskGraphQLDataset test done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderDataset(Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, tokenizer, type_path='train_spider.json', block_size=102):\n",
    "        'Initialization'\n",
    "        super(SpiderDataset, ).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.source = []\n",
    "        self.target = []\n",
    "        spider_path = './spider/'\n",
    "        path = spider_path + type_path\n",
    "        # TODO open up tables.json\n",
    "        # its a list of tables\n",
    "        # group by db_id \n",
    "        # grab column name from column_names_original ( each column name is a list of two. and the 2nd index {1} is the column name )\n",
    "        # grab table names from table_names (^ same as above )\n",
    "        # concat both with the english question (table names + <c> + column names + <q> english question)\n",
    "        # tokenize\n",
    "\n",
    "        # Maybe try making making more structure \n",
    "        # in the concat by using primary_keys and foreign_keys \n",
    "\n",
    "        tables_path = spider_path + 'tables.json'\n",
    "\n",
    "        with open(path, 'r') as f, open(tables_path, 'r') as t:\n",
    "          databases = json.load(t)\n",
    "          data = json.load(f)\n",
    "\n",
    "          #groupby db_id \n",
    "          grouped_dbs = {}\n",
    "          for db in databases:\n",
    "            grouped_dbs[db['db_id']] = db\n",
    "          # print(grouped_dbs)\n",
    "          # end grop tables\n",
    "\n",
    "          for element in data:\n",
    "            db = grouped_dbs[element['db_id']]\n",
    "\n",
    "            # tables_names = \" \".join(db['table_names_original'])\n",
    "            db_tables = db['table_names_original']\n",
    "\n",
    "            # columns_names = \" \".join([column_name[1] for column_name in db['column_names_original'] ])\n",
    "            tables_with_columns = ''\n",
    "            for table_id, group in itertools.groupby(db['column_names_original'], lambda x: x[0]):\n",
    "              if table_id == -1:\n",
    "                continue\n",
    "\n",
    "              columns_names = \" \".join([column_name[1] for column_name in group ])\n",
    "              tables_with_columns += '<t> ' + db_tables[table_id] + ' <c> ' + columns_names + ' </c> ' + '</t> '\n",
    "\n",
    "\n",
    "            # group columns with tables. \n",
    "\n",
    "            db_with_question = 'translate English to SQL: ' + element['question'] + ' ' + tables_with_columns\n",
    "            # question_with_schema = 'translate English to GraphQL: ' + element['question']  + ' ' + ' '.join(self.name_to_schema[element['schemaId']]) + ' </s>'\n",
    "\n",
    "            tokenized_s = tokenizer.batch_encode_plus([db_with_question],max_length=1024, padding='max_length', truncation=True,return_tensors='pt')\n",
    "            # what is the largest example size?\n",
    "            # the alternative is to collate\n",
    "            #might need to collate\n",
    "            self.source.append(tokenized_s)\n",
    "\n",
    "            tokenized_t = tokenizer.batch_encode_plus([element['query']],max_length=block_size, padding='max_length', truncation=True,return_tensors='pt')\n",
    "            self.target.append(tokenized_t)\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.source)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        source_ids = self.source[index]['input_ids'].squeeze()\n",
    "        target_ids = self.target[index]['input_ids'].squeeze()\n",
    "        src_mask = self.source[index]['attention_mask'].squeeze()\n",
    "        return { 'source_ids': source_ids,\n",
    "                'source_mask': src_mask,\n",
    "                'target_ids': target_ids,\n",
    "                'target_ids_y': target_ids}\n",
    "\n",
    "\n",
    "# # In[38]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_state:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "    dataset = SpiderDataset(tokenizer=tokenizer , type_path='train_spider.json', block_size=102)\n",
    "\n",
    "    length = dataset.__len__()\n",
    "    item = dataset.__getitem__(0)\n",
    "    print(\"SpiderDataset test done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoSQLMaskDataset(Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, tokenizer, type_path='cosql_train.json', block_size=64):\n",
    "        'Initialization'\n",
    "        super(CoSQLMaskDataset, ).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.source = []\n",
    "        self.target = []\n",
    "        path = './cosql_dataset/sql_state_tracking/' + type_path\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "          data = json.load(f)\n",
    "          for element in data:\n",
    "            for interaction in element['interaction']:\n",
    "              # repeat the squence for the amount of tokens. \n",
    "              # loop through those sequences and replace a different token in each one. \n",
    "              # the target will be that token. \n",
    "              utterance = interaction['query']\n",
    "              # tokens = utterance.split()\n",
    "              encoded_source = tokenizer.encode(utterance, max_length=block_size, padding='max_length', truncation=True, return_tensors='pt').squeeze()\n",
    "              token_count = encoded_source.shape[0]\n",
    "              # print(encoded_source.shape)\n",
    "              repeated_utterance = [encoded_source for _ in range(token_count)]\n",
    "              for pos in range(1, token_count):\n",
    "                encoded_source = repeated_utterance[pos].clone()\n",
    "                target_id = encoded_source[pos].item()\n",
    "                if target_id == tokenizer.eos_token_id:\n",
    "                  break\n",
    "                # encoded_source[pos] = tokenizer.mask_token_id\n",
    "                # self.target.append(target_id)\n",
    "                # self.source.append(encoded_source)\n",
    "\n",
    "                encoded_source[pos] = tokenizer.mask_token_id\n",
    "                decoded_target = ''.join(tokenizer.convert_ids_to_tokens([target_id]))\n",
    "                encoded_target = tokenizer.encode(decoded_target, return_tensors='pt', max_length=4, padding='max_length', truncation=True).squeeze() # should always be of size 1\n",
    "                self.target.append(encoded_target)\n",
    "                self.source.append(encoded_source)\n",
    "\n",
    "                # repeated_utterance[pos][pos] = target_token # so that the next iteration the previous token is correct\n",
    "\n",
    "                \n",
    "          \n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.source)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        source_ids = self.source[index]#['input_ids'].squeeze()\n",
    "        target_id = self.target[index]#['input_ids'].squeeze()\n",
    "        # src_mask = self.source[index]['attention_mask'].squeeze()\n",
    "        return { 'source_ids': source_ids,\n",
    "                'target_id': target_id}\n",
    "                # 'source_mask': src_mask,\n",
    "                # 'target_ids': target_ids,\n",
    "                # 'target_ids_y': target_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_state:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "    special_tokens_dict = tokenizer.special_tokens_map # the issue could be here, might need to copy.\n",
    "    special_tokens_dict['mask_token'] = '<mask>'\n",
    "    special_tokens_dict['additional_special_tokens'] = ['<t>', '</t>', '<a>', '</a>']\n",
    "    tokenizer.add_tokens(['{', '}', '<c>', '</c>'])\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    #model.resize_token_embeddings(len(tokenizer))\n",
    "    print(tokenizer.mask_token)\n",
    "\n",
    "    dataset = CoSQLMaskDataset(tokenizer=tokenizer , type_path='cosql_train.json', block_size=64)\n",
    "\n",
    "    length = dataset.__len__()\n",
    "    item = dataset.__getitem__(0)\n",
    "    print(\"CoSQLMaskDataset test done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5MultiSPModel(pl.LightningModule):\n",
    "  def __init__(self, hyperparams, task='denoise', test_flag='graphql', train_sampler=None, batch_size=2,temperature=1.0,top_k=50, top_p=1.0, num_beams=1 ):\n",
    "    super(T5MultiSPModel, self).__init__()\n",
    "\n",
    "    self.temperature = temperature\n",
    "    self.top_k = top_k\n",
    "    self.top_p = top_p\n",
    "    self.num_beams = num_beams\n",
    "\n",
    "    self.hyperparams = hyperparams\n",
    "\n",
    "    self.task = task\n",
    "    self.test_flag = test_flag\n",
    "    self.train_sampler = train_sampler\n",
    "    self.batch_size = batch_size\n",
    "    if self.task == 'finetune':\n",
    "      self.model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "    else: \n",
    "      self.model = T5ForConditionalGeneration.from_pretrained('t5-base') # no output past? \n",
    "\n",
    "    self.tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    \n",
    "    self.criterion = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    self.add_special_tokens()\n",
    "\n",
    "  def forward(\n",
    "    self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n",
    "    ):\n",
    "    return self.model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        decoder_attention_mask=decoder_attention_mask,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "  def add_special_tokens(self):\n",
    "    # new special tokens\n",
    "    special_tokens_dict = self.tokenizer.special_tokens_map # the issue could be here, might need to copy.\n",
    "    special_tokens_dict['mask_token'] = '<mask>'\n",
    "    special_tokens_dict['additional_special_tokens'] = ['<t>', '</t>', '<a>', '</a>']\n",
    "    self.tokenizer.add_tokens(['{', '}', '<c>', '</c>'])\n",
    "    self.tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "  def _step(self, batch):\n",
    "    if self.task == 'finetune':\n",
    "      pad_token_id = self.tokenizer.pad_token_id\n",
    "      source_ids, source_mask, y = batch[\"source_ids\"], batch[\"source_mask\"], batch[\"target_ids\"]\n",
    "      # y_ids = y[:, :-1].contiguous()\n",
    "      labels = y[:, :].clone()\n",
    "      labels[y[:, :] == pad_token_id] = -100\n",
    "      # attention_mask is for ignore padding on source_ids \n",
    "      # labels need to have pad_token ignored manually by setting to -100\n",
    "      # todo check the ignore token for forward\n",
    "      # seems like decoder_input_ids can be removed. \n",
    "      outputs = self(source_ids, attention_mask=source_mask, labels=labels,)\n",
    "\n",
    "      loss = outputs[0]\n",
    "\n",
    "    else: \n",
    "      y = batch['target_id']\n",
    "      labels = y[:, :].clone()\n",
    "      labels[y[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "      loss = self(\n",
    "          input_ids=batch[\"source_ids\"],\n",
    "          labels=labels\n",
    "      )[0]\n",
    "\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "\n",
    "    tensorboard_logs = {\"train_loss\": loss}\n",
    "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "\n",
    "    print(f'Validation step called, batch_idx: {batch_idx}, loss: {loss.item()}')\n",
    "\n",
    "    return {\"val_loss\": loss}\n",
    "\n",
    "\n",
    "  def on_validation_epoch_end(self, outputs=None):\n",
    "    if not outputs:\n",
    "        print(\"Empty outputs list.\")\n",
    "        return\n",
    "    print(\"outputs \" + str(outputs))\n",
    "    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "    # if self.task == 'finetune':\n",
    "    #   avg_acc = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
    "    #   tensorboard_logs = {\"val_loss\": avg_loss, \"avg_val_acc\": avg_acc}\n",
    "    #   return {\"progress_bar\": tensorboard_logs, \"log\": tensorboard_logs}\n",
    "    # else:\n",
    "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "    return {'progress_bar': tensorboard_logs, 'log': tensorboard_logs }\n",
    "    \n",
    "\n",
    "  # def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
    "  #   if self.trainer:\n",
    "  #     xm.optimizer_step(optimizer)\n",
    "  #   else:\n",
    "  #     optimizer.step()\n",
    "  #   optimizer.zero_grad()\n",
    "  #   self.lr_scheduler.step()\n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    t_total = len(self.train_dataloader()) * self.trainer.max_epochs * self.trainer.limit_train_batches\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        {\"params\": [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hyperparams.lr, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=t_total\n",
    "    )\n",
    "    self.lr_scheduler = scheduler\n",
    "    return [optimizer] #, [scheduler]\n",
    "\n",
    "  def _generate_step(self, batch):\n",
    "    generated_ids = self.model.generate(\n",
    "        batch[\"source_ids\"],\n",
    "        attention_mask=batch[\"source_mask\"],\n",
    "        num_beams=self.num_beams,\n",
    "        max_length=1000,\n",
    "        temperature=self.temperature,\n",
    "        top_k=self.top_k,\n",
    "        top_p=self.top_p,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    preds = [\n",
    "        self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for g in generated_ids\n",
    "    ]\n",
    "    target = [\n",
    "        self.tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for t in batch[\"target_ids\"]\n",
    "    ]\n",
    "    return (preds, target)\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    preds, target = self._generate_step(batch)\n",
    "    loss = self._step(batch)\n",
    "    if self.test_flag == 'graphql':\n",
    "      accuracy = exact_match.exact_match_accuracy(preds,target)\n",
    "      return {\"test_loss\": loss, \"test_accuracy\": torch.tensor(accuracy)}\n",
    "    else: \n",
    "      return {\"test_loss\": loss, \"preds\": preds, \"target\": target }\n",
    "\n",
    "  # def test_end(self, outputs):\n",
    "  #   return self.validation_end(outputs)\n",
    "\n",
    "\n",
    "  def test_epoch_end(self, outputs):\n",
    "    avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "    \n",
    "    if self.test_flag == 'graphql':\n",
    "      avg_acc = torch.stack([x[\"test_accuracy\"] for x in outputs]).mean()\n",
    "      tensorboard_logs = {\"test_loss\": avg_loss, \"test_acc\": avg_acc}\n",
    "      return {\"progress_bar\": tensorboard_logs, \"log\": tensorboard_logs}\n",
    "\n",
    "    else:\n",
    "      output_test_predictions_file = os.path.join(os.getcwd(), \"test_predictions.txt\")\n",
    "      with open(output_test_predictions_file, \"w+\") as p_writer:\n",
    "          for output_batch in outputs:\n",
    "              p_writer.writelines(s + \"\\n\" for s in output_batch[\"preds\"])\n",
    "          p_writer.close()\n",
    "      tensorboard_logs = {\"test_loss\": avg_loss}\n",
    "      return {\"progress_bar\": tensorboard_logs, \"log\": tensorboard_logs}\n",
    "\n",
    "  def prepare_data(self):\n",
    "    if self.task == 'finetune':\n",
    "      self.train_dataset_g = TextToGraphQLDataset(self.tokenizer)\n",
    "      self.val_dataset_g = TextToGraphQLDataset(self.tokenizer, type_path='dev.json')\n",
    "      self.test_dataset_g = TextToGraphQLDataset(self.tokenizer, type_path='dev.json')\n",
    "\n",
    "      self.train_dataset_s = SpiderDataset(self.tokenizer)\n",
    "      self.val_dataset_s = SpiderDataset(self.tokenizer, type_path='dev.json')\n",
    "      self.test_dataset_s = SpiderDataset(self.tokenizer, type_path='dev.json')\n",
    "\n",
    "      self.train_dataset = ConcatDataset([self.train_dataset_g,self.train_dataset_s])\n",
    "      self.val_dataset = ConcatDataset([self.val_dataset_g, self.val_dataset_s])\n",
    "      # self.test_dataset = ConcatDataset([test_dataset_g, test_dataset_s])\n",
    "      if self.test_flag == 'graphql':\n",
    "        self.test_dataset = self.test_dataset_g\n",
    "      else:\n",
    "        self.test_dataset = self.test_dataset_s\n",
    "      \n",
    "    else:\n",
    "      train_dataset_g = MaskGraphQLDataset(self.tokenizer)\n",
    "      val_dataset_g = MaskGraphQLDataset(self.tokenizer, type_path='dev.json')\n",
    "\n",
    "      train_dataset_s = CoSQLMaskDataset(self.tokenizer)\n",
    "      val_dataset_s = CoSQLMaskDataset(self.tokenizer, type_path='cosql_dev.json')\n",
    "\n",
    "      self.train_dataset = ConcatDataset([train_dataset_g, train_dataset_s])\n",
    "      self.val_dataset = ConcatDataset([val_dataset_g,val_dataset_s])\n",
    "\n",
    "  @staticmethod\n",
    "  def custom_collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    collated_batch = {}\n",
    "\n",
    "    for key in keys:\n",
    "        if key in ['source_ids', 'target_ids']:\n",
    "            max_length = max([len(sample[key]) for sample in batch])\n",
    "            padded_tensors = [torch.cat([sample[key], torch.zeros(max_length - len(sample[key]), dtype=torch.long)], dim=0) for sample in batch]\n",
    "            collated_batch[key] = torch.stack(padded_tensors, dim=0)\n",
    "        else:\n",
    "            max_length = max([len(sample[key]) for sample in batch])\n",
    "            padded_tensors = [torch.cat([sample[key], torch.zeros(max_length - len(sample[key]), dtype=torch.long)], dim=0) for sample in batch]\n",
    "            collated_batch[key] = torch.stack(padded_tensors, dim=0)\n",
    "\n",
    "    return collated_batch\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.custom_collate_fn, num_workers=0)\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(self.val_dataset, batch_size=self.batch_size, collate_fn=self.custom_collate_fn, num_workers=0)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.custom_collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ba50079d0f086540\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ba50079d0f086540\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir lightning_logs/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We initialize the T5MultiSPModel(hyperparams,batch_size=32)\n"
     ]
    }
   ],
   "source": [
    "hyperparams = argparse.Namespace(**{'lr': 0.0004365158322401656}) # for 3 epochs\n",
    "\n",
    "# # system = ConvBartSystem(dataset, train_sampler, batch_size=2)\n",
    "system = T5MultiSPModel(hyperparams,batch_size=32)\n",
    "print(\"We initialize the T5MultiSPModel(hyperparams,batch_size=32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logger\n",
    "logger = TensorBoardLogger(\"lightning_logs/\")\n",
    "# Pass the logger to the Trainer\n",
    "trainer = pl.Trainer(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model weights loaded from model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('model_weights.pth'):\n",
    "    system.load_state_dict(torch.load('model_weights.pth'))\n",
    "    print(\"model weights loaded from model_weights.pth\")\n",
    "\n",
    "else:\n",
    "    # If the weights file doesn't exist, train the model and save the weights after training\n",
    "    print(\"lets train this model!\")\n",
    "    if (use_gpu):\n",
    "      trainer = Trainer(accelerator='gpu', max_epochs=1, log_every_n_steps=1, limit_train_batches=0.2, gpus=1)\n",
    "    else:\n",
    "      trainer = Trainer(max_epochs=1, log_every_n_steps=1, limit_train_batches=0.2)\n",
    "    trainer.fit(system)\n",
    "    torch.save(system.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyps\n",
      "['{']\n"
     ]
    }
   ],
   "source": [
    "inputs = system.val_dataset[0]\n",
    "system.tokenizer.decode(inputs['source_ids'])\n",
    "\n",
    "if(use_gpu == True):\n",
    "  system.model = system.model.cuda()\n",
    "else:\n",
    "  system.model = system.model.cpu()\n",
    "generated_ids = system.model.generate(inputs['source_ids'].unsqueeze(0), num_beams=5, repetition_penalty=1.0, max_length=56, early_stopping=True)\n",
    "# # # summary_text = system.tokenizer.decode(generated_ids[0])\n",
    "\n",
    "hyps = [system.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in generated_ids]\n",
    "\n",
    "print(\"hyps\")\n",
    "print(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is allready fine-tuned, loading weights...\n",
      "fine_tuned_model_weights.pth loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('fine_tuned_model_weights.pth'):\n",
    "    # Load the model weights if the file exists\n",
    "  print(\"Model is allready fine-tuned, loading weights...\")\n",
    "  system.load_state_dict(torch.load('fine_tuned_model_weights.pth'))\n",
    "  print(\"fine_tuned_model_weights.pth loaded\")\n",
    "\n",
    "else:\n",
    "  print(\"Let's fine-tune this model!\")\n",
    "  if(use_gpu):\n",
    "    trainer = Trainer(gpus=1, max_epochs=5, progress_bar_refresh_rate=1, val_check_interval=0.5)\n",
    "  else:\n",
    "    trainer = Trainer(max_epochs=5, progress_bar_refresh_rate=1, val_check_interval=0.5)\n",
    "  trainer.fit(system)\n",
    "  torch.save(system.state_dict(), 'fine_tuned_model_weights.pth')\n",
    "  \n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt, schemaId):\n",
    "\n",
    "    if system.train_dataset_g.name_to_schema[schemaId] is not None:\n",
    "        input_string = system.train_dataset_g.get_question_with_schema(prompt, schemaId)\n",
    "    elif system.dev_dataset.name_to_schema[schemaId] is not None:\n",
    "        input_string = system.val_dataset_g.get_question_with_schema(prompt, schemaId)\n",
    "    #print(input_string)\n",
    "\n",
    "    inputs = system.tokenizer.batch_encode_plus([input_string], max_length=1024, return_tensors='pt')['input_ids']\n",
    "    #print(inputs.shape)\n",
    "\n",
    "    if(use_gpu == True):\n",
    "      generated_ids = system.model.generate(inputs.cuda(), num_beams=3, repetition_penalty=1.0, max_length=1000, early_stopping=True)\n",
    "    else:\n",
    "      generated_ids = system.model.generate(inputs, num_beams=3, repetition_penalty=1.0, max_length=1000, early_stopping=True)\n",
    "    hyps = [system.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in generated_ids]\n",
    "    dict_res = {\"prediction\": hyps[0]}\n",
    "    return dict_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>queries_shifted_order</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query { hiring { employee_id is_full_time shop_id start_from } }</td>\n",
       "      <td>query { hiring { employee_id shop_id is_full_time start_from } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query { teacher ( order_by : { age : asc } ) { name } }</td>\n",
       "      <td>query { teacher ( order_by : { age : asc } ) { name } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query { pets ( where : { pet_age : { _gt : 1 } } ) { petid weight } }</td>\n",
       "      <td>query { pets ( where : { pet_age : { _gt : 1 } } ) { weight petid } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query { singer_aggregate { aggregate { count } } }</td>\n",
       "      <td>query { singer_aggregate { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query { singer { birth_year citizenship } }</td>\n",
       "      <td>query { singer { citizenship birth_year } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>query { ref_template_types { template_type_code template_type_description } }</td>\n",
       "      <td>query { ref_template_types { template_type_description template_type_code } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>query { airports ( where : { city : { _eq : \"Anthony\" } } ) { airportcode airportname }}</td>\n",
       "      <td>query { airports ( where : { city : { _eq : \"Anthony\" } } ) { airportname airportcode }}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>query { singer ( where : { song_name : { _like : \"%Hey%\" } } ) { name country } }</td>\n",
       "      <td>query { singer ( where : { song_name : { _like : \"%Hey%\" } } ) { country name } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>query { players ( order_by : { birth_date : asc } ) { first_name last_name } }</td>\n",
       "      <td>query { players ( order_by : { birth_date : asc } ) { last_name first_name } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>query { battle ( where : { bulgarian_commander : { _neq : \"Boril\" } } ) { name result } }</td>\n",
       "      <td>query { battle ( where : { bulgarian_commander : { _neq : \"Boril\" } } ) { result name } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>query { stadium ( where : { capacity : { _gte : 5000 , _lte : 10000 } } ) { location name } }</td>\n",
       "      <td>query { stadium ( where : { capacity : { _gte : 5000 , _lte : 10000 } } ) { name location } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>query { country_aggregate ( where : { continent : { _eq : \"Africa\" } } ) { aggregate { count } } }</td>\n",
       "      <td>query { country_aggregate ( where : { continent : { _eq : \"Africa\" } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }</td>\n",
       "      <td>query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }</td>\n",
       "      <td>query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>query { country_aggregate ( where : { governmentform : { _eq : \"Republic\" } } ) { aggregate { count } } }</td>\n",
       "      <td>query { country_aggregate ( where : { governmentform : { _eq : \"Republic\" } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>query { airlines_aggregate ( where : { _and : { flights : { sourceairport : { _eq : \"AHD\" } } , airline : { _eq : \"United Airlines\" } } } ) { aggregate { count } } }</td>\n",
       "      <td>query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { sourceairport : { _eq : \"AHD\" } } } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { destairport : { _eq : \"ASY\" } } } } ) { aggregate { count } } }</td>\n",
       "      <td>query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { destairport : { _eq : \"ASY\" } } } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>query { paragraphs_aggregate ( where : { document : { document_name : { _eq : \"Summer Show\" } } } ) { aggregate { count } } }</td>\n",
       "      <td>query { paragraphs_aggregate ( where : { document : { document_name : { _eq : \"Summer Show\" } } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>query { country_aggregate ( where : { _and : { countrylanguages : { isofficial : { _eq : \"T\" } } , name : { _eq : \"Afghanistan\" } } } ) { aggregate { count } } }</td>\n",
       "      <td>query { country_aggregate ( where : { _and : { name : { _eq : \"Afghanistan\" } , countrylanguages : { isofficial : { _eq : \"T\" } } } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>query { airlines_aggregate ( where : { _and : { flights : { sourceairport : { _eq : \"AHD\" } } , airline : { _eq : \"United Airlines\" } } } ) { aggregate { count } } }</td>\n",
       "      <td>query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { sourceairport : { _eq : \"AHD\" } } } } ) { aggregate { count } } }</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  queries                                                                                                                                                  queries_shifted_order  result\n",
       "0                                                                                                        query { hiring { employee_id is_full_time shop_id start_from } }                                                                                                       query { hiring { employee_id shop_id is_full_time start_from } }    True\n",
       "1                                                                                                                 query { teacher ( order_by : { age : asc } ) { name } }                                                                                                                query { teacher ( order_by : { age : asc } ) { name } }    True\n",
       "2                                                                                                   query { pets ( where : { pet_age : { _gt : 1 } } ) { petid weight } }                                                                                                  query { pets ( where : { pet_age : { _gt : 1 } } ) { weight petid } }    True\n",
       "3                                                                                                                      query { singer_aggregate { aggregate { count } } }                                                                                                                     query { singer_aggregate { aggregate { count } } }    True\n",
       "4                                                                                                                             query { singer { birth_year citizenship } }                                                                                                                            query { singer { citizenship birth_year } }    True\n",
       "5                                                                                           query { ref_template_types { template_type_code template_type_description } }                                                                                          query { ref_template_types { template_type_description template_type_code } }    True\n",
       "6                                                                                query { airports ( where : { city : { _eq : \"Anthony\" } } ) { airportcode airportname }}                                                                               query { airports ( where : { city : { _eq : \"Anthony\" } } ) { airportname airportcode }}    True\n",
       "7                                                                                       query { singer ( where : { song_name : { _like : \"%Hey%\" } } ) { name country } }                                                                                      query { singer ( where : { song_name : { _like : \"%Hey%\" } } ) { country name } }    True\n",
       "8                                                                                          query { players ( order_by : { birth_date : asc } ) { first_name last_name } }                                                                                         query { players ( order_by : { birth_date : asc } ) { last_name first_name } }    True\n",
       "9                                                                               query { battle ( where : { bulgarian_commander : { _neq : \"Boril\" } } ) { name result } }                                                                              query { battle ( where : { bulgarian_commander : { _neq : \"Boril\" } } ) { result name } }    True\n",
       "10                                                                          query { stadium ( where : { capacity : { _gte : 5000 , _lte : 10000 } } ) { location name } }                                                                          query { stadium ( where : { capacity : { _gte : 5000 , _lte : 10000 } } ) { name location } }    True\n",
       "11                                                                     query { country_aggregate ( where : { continent : { _eq : \"Africa\" } } ) { aggregate { count } } }                                                                     query { country_aggregate ( where : { continent : { _eq : \"Africa\" } } ) { aggregate { count } } }    True\n",
       "12                                                                         query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }                                                                         query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }    True\n",
       "13                                                                         query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }                                                                         query { airlines_aggregate ( where : { country : { _eq : \"USA\" } } ) { aggregate { count } } }    True\n",
       "14                                                              query { country_aggregate ( where : { governmentform : { _eq : \"Republic\" } } ) { aggregate { count } } }                                                              query { country_aggregate ( where : { governmentform : { _eq : \"Republic\" } } ) { aggregate { count } } }    True\n",
       "15  query { airlines_aggregate ( where : { _and : { flights : { sourceairport : { _eq : \"AHD\" } } , airline : { _eq : \"United Airlines\" } } } ) { aggregate { count } } }  query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { sourceairport : { _eq : \"AHD\" } } } } ) { aggregate { count } } }    True\n",
       "16    query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { destairport : { _eq : \"ASY\" } } } } ) { aggregate { count } } }    query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { destairport : { _eq : \"ASY\" } } } } ) { aggregate { count } } }    True\n",
       "17                                          query { paragraphs_aggregate ( where : { document : { document_name : { _eq : \"Summer Show\" } } } ) { aggregate { count } } }                                          query { paragraphs_aggregate ( where : { document : { document_name : { _eq : \"Summer Show\" } } } ) { aggregate { count } } }    True\n",
       "18      query { country_aggregate ( where : { _and : { countrylanguages : { isofficial : { _eq : \"T\" } } , name : { _eq : \"Afghanistan\" } } } ) { aggregate { count } } }      query { country_aggregate ( where : { _and : { name : { _eq : \"Afghanistan\" } , countrylanguages : { isofficial : { _eq : \"T\" } } } } ) { aggregate { count } } }    True\n",
       "19  query { airlines_aggregate ( where : { _and : { flights : { sourceairport : { _eq : \"AHD\" } } , airline : { _eq : \"United Airlines\" } } } ) { aggregate { count } } }  query { airlines_aggregate ( where : { _and : { airline : { _eq : \"United Airlines\" } , flights : { sourceairport : { _eq : \"AHD\" } } } } ) { aggregate { count } } }    True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to next line\n",
    "pd.set_option('display.max_colwidth', None)  # Show the full content of each cell\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Create a datafame called test_df from semantic_matching_queries.csv\n",
    "\n",
    "test_df = pd.read_csv('semantic_match_test_queries.csv')\n",
    "\n",
    "test_df.head()\n",
    "\n",
    "# for every row in the dataframe call are_queries_semantically_same with queries and queries_shifted_order. Create a new column called result and set it to the result of the function call\n",
    "\n",
    "test_df['result'] = test_df.apply(lambda row: are_queries_semantically_same(row['queries'], row['queries_shifted_order']), axis=1)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def custom_test(dataset_path):\n",
    "    # Load the dev dataset\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dev_data = json.load(f)\n",
    "\n",
    "    exact_match = []\n",
    "    semantic_match = []\n",
    "\n",
    "    for example in dev_data:\n",
    "        prompt = example[\"question\"]\n",
    "        schemaId = example[\"schemaId\"]\n",
    "        query = example[\"query\"]\n",
    "\n",
    "        prediction = predict(prompt, schemaId)[\"prediction\"]\n",
    "\n",
    "        exact_match.append(1 if prediction == query else 0)\n",
    "        semantic_match.append(1 if are_queries_semantically_same(prediction, query) else 0)\n",
    "\n",
    "    def calculate_metrics(match_results):\n",
    "        accuracy = accuracy_score(match_results, np.ones(len(match_results)))\n",
    "        f1 = f1_score(match_results, np.ones(len(match_results)))\n",
    "        precision = precision_score(match_results, np.ones(len(match_results)))\n",
    "        recall = recall_score(match_results, np.ones(len(match_results)))\n",
    "        return accuracy, f1, precision, recall\n",
    "\n",
    "    # Calculate evaluation metrics for exact match\n",
    "    exact_accuracy, exact_f1, exact_precision, exact_recall = calculate_metrics(exact_match)\n",
    "\n",
    "    # Calculate evaluation metrics for semantic match\n",
    "    semantic_accuracy, semantic_f1, semantic_precision, semantic_recall = calculate_metrics(semantic_match)\n",
    "\n",
    "    print(\"Exact match:\")\n",
    "    print(f\"Accuracy: {exact_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nSemantic match:\")\n",
    "    print(f\"Accuracy: {semantic_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def custom_test_df(df):\n",
    "    exact_match = []\n",
    "    semantic_match = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        prompt = row[\"question\"]\n",
    "        schemaId = row[\"schemaId\"]\n",
    "        query = row[\"query\"]\n",
    "\n",
    "        prediction = predict(prompt, schemaId)[\"prediction\"]\n",
    "\n",
    "        exact_match.append(1 if prediction == query else 0)\n",
    "        df.loc[index, 'exact_match'] = 1 if prediction == query else 0\n",
    "\n",
    "        semantic_match.append(1 if are_queries_semantically_same(prediction, query) else 0)\n",
    "        df.loc[index, 'semantic_match'] = 1 if are_queries_semantically_same(prediction, query) else 0\n",
    "\n",
    "        # Add predicted query to the dataframe\n",
    "        df.loc[index, 'predicted_query'] = prediction\n",
    "\n",
    "    def calculate_metrics(match_results):\n",
    "        accuracy = accuracy_score(match_results, np.ones(len(match_results)))\n",
    "        return accuracy\n",
    "\n",
    "    # Calculate evaluation metrics for exact match\n",
    "    exact_accuracy = calculate_metrics(exact_match)\n",
    "\n",
    "    # Calculate evaluation metrics for semantic match\n",
    "    semantic_accuracy = calculate_metrics(semantic_match)\n",
    "\n",
    "    return exact_accuracy, semantic_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.task = 'finetune'\n",
    "system.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the result\n",
      "{'prediction': 'query { ship_aggregate ( where : { tonnage : { _lt : \"Captured\" } } ) { aggregate { count } } }'}\n"
     ]
    }
   ],
   "source": [
    "hardcoded_schemaId = \"battle_death\"\n",
    "hardcoded_prompt = \"How many ships ended up being not 'Captured'?\"\n",
    "\n",
    "result = predict(hardcoded_prompt, hardcoded_schemaId)\n",
    "print(\"this is the result\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset_path = 'SPEGQL-dataset/dataset/dev.json'\n",
    "\n",
    "#custom_test(dev_dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3819444444444444, 0.39814814814814814)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe from dev_df.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dev_df = pd.read_csv('dev_df.csv')\n",
    "\n",
    "# Add two empty columns to the dataframe: exact match and semantic match\n",
    "\n",
    "dev_df['exact_match'] = \"\"\n",
    "dev_df['semantic_match'] = \"\"\n",
    "\n",
    "#custom_test_df(dev_df)\n",
    "\n",
    "# Save the dataframe to a csv file for later use. Call it dev_df__with_results.csv\n",
    "\n",
    "# dev_df.to_csv('dev_df_with_results.csv')\n",
    "\n",
    "# Create a dataframe from dev_df with 5% of the data\n",
    "\n",
    "# dev_df_20 = dev_df.sample(frac=0.02)\n",
    "\n",
    "custom_test_df(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to next line\n",
    "pd.set_option('display.max_colwidth', None)  # Show the full content of each cell\n",
    "\n",
    "# How many rows are in the dataframe?\n",
    "\n",
    "# len(dev_df_20.index)\n",
    "\n",
    "# # How many exact matches are there?\n",
    "\n",
    "# dev_df_20['exact_match'].sum()\n",
    "\n",
    "# # How many semantic matches are there?\n",
    "\n",
    "# dev_df_20['semantic_match'].sum()\n",
    "\n",
    "dev_df.to_csv('dev_df_with_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have this function that predicts the corresponding query to a question.\n",
    "# I pass this data frame to the function. The data frame consists of the following columns:\n",
    "\n",
    "# I wish to know how well it performs on the the different properties: question_length_bucket, nesting level, num_args, schema length, schema complexity\n",
    "# Additionally, I wish to know how well it performs on the interactions of these properties. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd51bf327c04802b512fe352f9afa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/jakobtolstrup/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/jakobtolstrup/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TextToGraphQLDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "# system.num_beams = 3\n",
    "# system.test_flag = 'graphql'\n",
    "# system.prepare_data()\n",
    "# trainer.test(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphql import parse\n",
    "from graphql.language.ast import ObjectValueNode, StringValueNode\n",
    "\n",
    "def are_queries_semantically_equivalent(query1, query2):\n",
    "    def extract_fields(selection_set):\n",
    "        fields = {}\n",
    "        for field in selection_set.selections:\n",
    "            if hasattr(field, \"selection_set\") and field.selection_set:\n",
    "                fields[field.name.value] = extract_fields(field.selection_set)\n",
    "            else:\n",
    "                fields[field.name.value] = None\n",
    "        return fields\n",
    "\n",
    "    def sort_query_fields(query_dict):\n",
    "        for key, value in query_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                query_dict[key] = sort_query_fields(value)\n",
    "        return dict(sorted(query_dict.items()))\n",
    "\n",
    "    def normalize_query(query):\n",
    "        return ''.join(query.split())\n",
    "\n",
    "    def extract_arguments(normalized_query):\n",
    "        args_start = normalized_query.find(\"(\")\n",
    "        args_end = normalized_query.rfind(\")\")\n",
    "        if args_start == -1 or args_end == -1:\n",
    "            return None\n",
    "        return normalized_query[args_start+1:args_end]\n",
    "\n",
    "    normalized_query1 = normalize_query(query1)\n",
    "    normalized_query2 = normalize_query(query2)\n",
    "\n",
    "    # Check if the arguments are identical\n",
    "    if extract_arguments(normalized_query1) != extract_arguments(normalized_query2):\n",
    "        return False\n",
    "\n",
    "    ast1 = parse(query1)\n",
    "    ast2 = parse(query2)\n",
    "\n",
    "    query1_dict = extract_fields(ast1.definitions[0].selection_set)\n",
    "    query2_dict = extract_fields(ast2.definitions[0].selection_set)\n",
    "\n",
    "    sorted_query1 = sort_query_fields(query1_dict)\n",
    "    sorted_query2 = sort_query_fields(query2_dict)\n",
    "\n",
    "    return sorted_query1 == sorted_query2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: PASSED\n",
      "Test 2: PASSED\n",
      "Test 3: PASSED\n",
      "Test 4: PASSED\n",
      "Test 5: PASSED\n",
      "Test 6: PASSED\n",
      "Test 7: PASSED\n",
      "Test 8: PASSED\n",
      "Test 9: PASSED\n",
      "Test 10: PASSED\n",
      "Test 11: PASSED\n",
      "Test 12: PASSED\n",
      "Test 13: PASSED\n",
      "Test 14: PASSED\n",
      "Test 15: PASSED\n",
      "Test 16: PASSED\n",
      "Test 17: PASSED\n",
      "Test 18: PASSED\n",
      "Test 19: PASSED\n",
      "Test 20: PASSED\n",
      "Test 21: PASSED\n",
      "Test 22: PASSED\n",
      "Test 23: PASSED\n",
      "Test 24: PASSED\n",
      "\n",
      "Total tests: 24\n",
      "Passed tests: 24\n",
      "Failed tests: 0\n"
     ]
    }
   ],
   "source": [
    "original_queries = [\n",
    "    'query { matches_aggregate { aggregate { count } } }',\n",
    "    'query { cartoon ( order_by : { title : asc } ) { title } }', \n",
    "    'query { highschooler ( where : { name : { _eq : \\\"Kyle\\\" } } ) { id } }',\n",
    "    'query { stadium_aggregate { aggregate { avg { capacity } max { capacity } } } }',\n",
    "    'query { flights ( where : { destairport : { _eq : \"APG\" } } ) { flight no } }',\n",
    "    'query { singer ( where : { citizenship : { _neq : \\\"France\\\" } } ) { name } }',\n",
    "    'query { paragraphs ( where : { paragraph_text : { _eq : \\\"Korea\\\" } } ) { other_details } }',\n",
    "    'query { people ( where : { nationality : { _eq : \\\"Russia\\\" } } ) { name } }',\n",
    "    'query { documents ( where : { template : { template_type_code : { _eq : \\\"BK\\\" } } } ) { document_name } }',\n",
    "    'query { ship_aggregate ( where : { disposition_of_ship : { _eq : \\\"Captured\\\" } } ) { aggregate { count } } }',\n",
    "    'query { flights ( where : { airlineByAirline : { airline : { _eq : \\\"United Airlines\\\" } } } ) { flightno } }',\n",
    "    'query { votes_aggregate ( where : { state : { _eq : \\\"CA\\\" } } ) { aggregate { max { created } } } }',\n",
    "    'query { visitor ( limit : 1 , order_by : { visits_aggregate : { max : { num_of_ticket : desc_nulls_last } } } ) { name age } }',\n",
    "    'query { templates ( where : { ref_template_type : { template_type_description : { _eq : \\\"Presentation\\\" } } } ) { template_id } }',\n",
    "    'query { templates ( where : { _or : [ { template_type_code : { _eq : \"PP\" } } , { template_type_code : { _eq : \"PPT\" } }] } ) { template_id } }',\n",
    "    'query { rankings ( limit : 1 , order_by : { tours : desc_nulls_last } ) { player { country_code first_name } } }',\n",
    "    'query { cars_data ( limit : 1 , order_by : { accelerate : asc } , where : { car_name : { model : { _eq : \\\"volvo\\\" } } } ) { cylinders } }',\n",
    "    'query { singer_aggregate ( where : { country : { _eq : \\\"France\\\" } } ) { aggregate { avg { age } min { age } max { age } } } }',\n",
    "    'query { singer ( where : { song_name : { _like : \\\"%Hey%\\\" } } ) { name country } }',\n",
    "    'query { teacher ( where : { _or : [ { age : { _eq : \\\"32\\\" } } , { age : { _eq : \\\"33\\\" } } ] } ) { name } }',\n",
    "    'query { teacher ( where : { course_arranges : { course : { course : { _eq : \\\"Math\\\" } } } } ) { name } }',\n",
    "    'query { documents ( where : { document_name : { _eq : \\\"Robbin CV\\\" } } ) { document_id template_id document_description } }',\n",
    "    'query { airlines_aggregate ( where : { _and : { airline : { _eq : \\\"United Airlines\\\" } , flights : { destairport : { _eq : \\\"ASY\\\" } } } } ) { aggregate { count } } }',\n",
    "    'query { museum_aggregate ( where : { _or : [ { open_year : { _gt : \\\"2013\\\" } } , { open_year : { _lt : \\\"2008\\\" } } ] } ) { aggregate { count } } }'\n",
    "]\n",
    "\n",
    "semantically_equivalent_original_queries = [\n",
    "    'query { matches_aggregate { aggregate { count } } }',\n",
    "    'query{cartoon(order_by:{title:asc}){title}}',\n",
    "    'query { highschooler ( where : { name : { _eq : \\\"Kyle\\\" } } ){ id } }',\n",
    "    'query{stadium_aggregate{aggregate{avg{capacity} max{capacity}}}}',\n",
    "    'query { flights ( where : { destairport : { _eq : \\\"APG\\\" } } ) { flight no } }',\n",
    "    'query{singer(where:{citizenship:{_neq:\\\"France\\\"}}){name}}',\n",
    "    'query { paragraphs ( where : { paragraph_text : { _eq : \\\"Korea\\\" } } ) { other_details } }',\n",
    "    'query{people(where:{nationality:{_eq:\\\"Russia\\\"}}){name}}',\n",
    "    'query { documents ( where : { template : { template_type_code : { _eq : \\\"BK\\\" } } } ) { document_name } }',\n",
    "    'query{ship_aggregate(where:{disposition_of_ship:{_eq:\\\"Captured\\\"}}){aggregate{count}}}',\n",
    "    'query { flights ( where : { airlineByAirline : { airline : { _eq : \\\"United Airlines\\\" } } } ) { flightno } }',\n",
    "    'query{votes_aggregate(where:{state:{_eq:\\\"CA\\\"}}){aggregate{max{created}}}}',\n",
    "    'query { visitor ( limit : 1 , order_by : { visits_aggregate : { max : { num_of_ticket : desc_nulls_last } } } ) { age name } }',\n",
    "    'query{templates(where:{ref_template_type:{template_type_description:{_eq:\\\"Presentation\\\"}}}){template_id}}',\n",
    "    'query { templates ( where : { _or : [ { template_type_code : { _eq : \\\"PP\\\" } } , { template_type_code : { _eq : \\\"PPT\\\" } }] } ) { template_id } }',\n",
    "    'query{rankings(limit:1,order_by:{tours:desc_nulls_last}){player{first_name country_code}}}',\n",
    "    'query { cars_data ( limit : 1 , order_by : { accelerate : asc } , where : { car_name : { model : { _eq : \\\"volvo\\\" } } } ) { cylinders } }',\n",
    "    'query{singer_aggregate(where:{country:{_eq:\\\"France\\\"}}){aggregate{avg{age}min{age}max{age}}}}',\n",
    "    'query { singer ( where : { song_name : { _like : \\\"%Hey%\\\" } } ) { name country } }',\n",
    "    'query{teacher(where:{_or:[{age:{_eq:\\\"32\\\"}},{age:{_eq:\\\"33\\\"}}]}){name}}',\n",
    "    'query { teacher ( where : { course_arranges : { course : { course : { _eq : \\\"Math\\\" } } } } ) { name } }',\n",
    "    'query{documents(where:{document_name:{_eq:\\\"Robbin CV\\\"}}){ document_description document_id template_id }}',\n",
    "    'query { airlines_aggregate ( where : { _and : { airline : { _eq : \\\"United Airlines\\\" } , flights : { destairport : { _eq : \\\"ASY\\\" } } } } ) { aggregate { count } } }',\n",
    "\t'query { museum_aggregate ( where : { _or : [ { open_year : { _gt : \\\"2013\\\" } } , { open_year : { _lt : \\\"2008\\\" } } ] } ) { aggregate { count } } }'\n",
    "]\n",
    "\n",
    "original_queries_expect_failure = [\n",
    "    'query { students ( limit : 1 , order_by : { date_left : asc } ) { first_name middle_name last_name } }',\n",
    "    'query { students ( limit : 1 , order_by : { date_left : asc } ) { first_name middle_name last_name } }',\n",
    "    'query { cartoon ( order_by : { title : asc } ) { title } }',\n",
    "    'query { cartoon ( order_by : { title : asc } ) { title } }',\n",
    "    'query { countrylanguage_aggregate ( where : { _and : { country : { indepyear : { _lt : \\\"1930\\\" } } , isofficial : { _eq : \\\"T\\\" } } } ) { aggregate { count } } }',\n",
    "    'query { countrylanguage ( where : { language : { _neq : \\\"English\\\" } } , distinct_on : countrycode ) { countrycode } }',\n",
    "    'query { matches_aggregate ( where : { _and : { winner_hand : { _eq : \\\"L\\\" } , tourney_name : { _eq : \\\"WTA Championships\\\" } } } ) { aggregate { count } } }',\n",
    "    'query { matches_aggregate ( where : { _and : { winner_hand : { _eq : \\\"L\\\" } , tourney_name : { _eq : \\\"WTA Championships\\\" } } } ) { aggregate { count } } }',\n",
    "    'query { documents_aggregate { aggregate { count } } }',\n",
    "    'query { documents { document_id document_name document_description } }',\n",
    "    'query { people ( order_by : { name : asc } ) { name birth_date } }',\n",
    "    'query { ref_template_types ( where : { template_type_code : { _eq : \\\"AD\\\" } } ) { template_type_description } }',\n",
    "    'query { countrylanguage ( where : { _and : { country : { headofstate : { _eq : \\\"Beatrix\\\" } } , isofficial : { _eq : \\\"T\\\" } } } ) { language } }',\n",
    "    'query { templates ( where : { _or : [ { template_type_code : { _eq : \\\"PP\\\" } } , { template_type_code : { _eq : \\\"PPT\\\" } } ] } ) { template_id } }',\n",
    "]\n",
    "\n",
    "revised_queries_expect_failure = [\n",
    "    'query { students ( limit : 1 , order_by : { date_left : desc } ) { first_name middle_name last_name } }',\n",
    "    'query { students ( limit : 2 , order_by : { date_left : asc } ) { first_name middle_name last_name } }',\n",
    "    'query { cartoon ( order_by : { title : desc } ) { title } }',\n",
    "    'query { cartoon { title } }',\n",
    "    'query { countrylanguage_aggregate ( where : { _and : { country : { indepyear : { _gt : \\\"1930\\\" } } , isofficial : { _eq : \\\"T\\\" } } } ) { aggregate { count } } }',\n",
    "    'query { countrylanguage ( where : { language : { _neq : \\\"French\\\" } } , distinct_on : countrycode ) { countrycode } }',\n",
    "    'query { matches_aggregate ( where : { _and : { winner_hand : { _eq : \\\"R\\\" } , tourney_name : { _eq : \\\"WTA Championships\\\" } } } ) { aggregate { count } } }',\n",
    "    'query { matches_aggregate ( where : { _and : { winner_hand : { _eq : \\\"L\\\" } , tourney_name : { _eq : \\\"Australian Open\\\" } } } ) { aggregate { count } } }',\n",
    "    'query { documents_aggregate { aggregate { sum } } }',\n",
    "    'query { documents { document_id document_name } }',\n",
    "    'query { people ( order_by : { birth_date : desc } ) { name email } }',\n",
    "    'query { ref_template_types ( where : { template_type_code : { _neq : \"AD\" } } ) { template_type_code } }',\n",
    "    'query { countrylanguage ( where : { _or : [ { country : { headofstate : { eq : \\\"Beatrix\\\" } } }, { isofficial : { _neq : \\\"T\\\" } } ] } ) { language } }',\n",
    "    'query { templates ( where : { _and : [ { template_type_code : { _neq : \"PP\" } } , { template_type_code : { _neq : \"PPT\" } } ] } ) { template_id template_type_code } }'\n",
    "]\n",
    "\n",
    "def test_queries(original_queries, revised_queries):\n",
    "    total_tests = len(original_queries)\n",
    "    passed_tests = 0\n",
    "\n",
    "    for i in range(total_tests):\n",
    "        original_query = original_queries[i]\n",
    "        revised_query = revised_queries[i]\n",
    "\n",
    "        if are_queries_semantically_equivalent(original_query, revised_query):\n",
    "            print(f\"Test {i + 1}: PASSED\")\n",
    "            passed_tests += 1\n",
    "        else:\n",
    "            print(f\"Test {i + 1}: FAILED\")\n",
    "\n",
    "    print(f\"\\nTotal tests: {total_tests}\")\n",
    "    print(f\"Passed tests: {passed_tests}\")\n",
    "    print(f\"Failed tests: {total_tests - passed_tests}\")\n",
    "\n",
    "test_queries(original_queries, semantically_equivalent_original_queries)\n",
    "#test_queries(original_queries_expect_failure, revised_queries_expect_failure)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7048a5d75593413cc54dc24206831079ac8905ffddb319c4eafd454be0ec5d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
